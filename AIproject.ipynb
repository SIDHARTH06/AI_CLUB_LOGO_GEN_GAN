{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzdesFvDFJ4YAlTDX7rc1p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDHARTH06/AI_CLUB_LOGO_GEN_GAN/blob/main/AIproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LseJbNuIWbLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea9215b-25e4-4c5c-d0c3-32d03294438a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "drive.mount('/content/gdrive')\n",
        "import keras\n",
        "from keras.layers import Input,Dense,Reshape,Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "img_rows=32\n",
        "img_cols=32\n",
        "channels=3\n",
        "img_shape=(img_rows,img_cols,channels)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNEYHm_hQ3i"
      },
      "source": [
        "hdf5_path=\"/content/gdrive/My Drive/LLD-icon.hdf5\"\n",
        "dataset=h5py.File(hdf5_path,\"r\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAxRJZuvZr90"
      },
      "source": [
        "def build_generator():  #generator model 3 layers and one final layer\n",
        "  noise_shape=(100,)\n",
        "  model=Sequential()\n",
        "  model.add(Dense(256,input_shape=noise_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(1024))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(np.prod(img_shape),activation='tanh'))\n",
        "  model.add(Reshape(img_shape))\n",
        "\n",
        "  model.summary()\n",
        "  noise=Input(shape=noise_shape)\n",
        "  img=model(noise)\n",
        "  \n",
        "  return Model(noise,img)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTpB-4FA1KpN"
      },
      "source": [
        "def build_discriminator(): #discriminator model 2 layers and one final layer\n",
        "  \n",
        "  model=Sequential()\n",
        "  model.add(Flatten(input_shape=img_shape))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.summary()\n",
        "  \n",
        "  img=Input(shape=img_shape)\n",
        "  validity=model(img)\n",
        "  return Model(img,validity)\n",
        "  "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAzEuhstH8ck"
      },
      "source": [
        "def train(epochs,batch_size=128,save_interval=500): #train function\n",
        "  images, labels = (dataset['data'], dataset['labels/resnet/rc_64'])\n",
        "  images=(np.transpose(images).astype(np.float32)-127.5)/127.5  #normalising the images rgb values to between -1 and 1\n",
        "  half_batch=int(batch_size/2)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    idx=np.random.randint(0,img_shape[0],half_batch)\n",
        "    imgs=images[idx]\n",
        "    noise=np.random.normal(0,1,(half_batch,100))\n",
        "\n",
        "    gen_imgs=generator.predict(noise)\n",
        "    d_loss_real=discriminator.train_on_batch(imgs,np.ones((half_batch,1)))\n",
        "    d_loss_fake=discriminator.train_on_batch(gen_imgs,np.zeroes((half_batch,1))) \n",
        "\n",
        "    d_loss=0.5*(np.add(d_loss_real,d_loss_fake)) \n",
        "    noise=np.random.normal(0,1,(batch_size,100))\n",
        "    valid_y=np.array([1]*batch_size)\n",
        "    g_loss=combined.train_on_batch(noise,valid_y)\n",
        "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "    if epoch%save_interval==0:\n",
        "      save_imgs(epoch)\n",
        "       "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTT9KscZwkdS"
      },
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='rgb')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/gan_%d.png\" % epoch)\n",
        "    plt.close()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wSxAi0y-79Z"
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H30_9VN1n-V",
        "outputId": "a691cc34-0a27-422a-d56f-f26582b5e455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = Adam(0.0002, 0.5)  #Learning rate and momentum.\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "generator = build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "z = Input(shape=(100,))   #Our random input to the generator\n",
        "img = generator(z)\n",
        "\n",
        "discriminator.trainable = False  \n",
        "\n",
        "valid = discriminator(img)\n",
        "train(epochs=100,batch_size=32,save_interval=10)\n",
        "generator.save('generator_model.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,704,961\n",
            "Trainable params: 1,704,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_46 (Dense)             (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 3072)              3148800   \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 32, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 3,838,720\n",
            "Trainable params: 3,835,136\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}