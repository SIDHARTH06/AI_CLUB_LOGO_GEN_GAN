{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm/kd2l2FslSOWa2OGb6KX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDHARTH06/AI_CLUB_LOGO_GEN_GAN/blob/main/AIproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LseJbNuIWbLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527a2568-21a9-4a3e-f77f-6842cad0bdd3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "drive.mount('/content/gdrive')\n",
        "import keras\n",
        "from keras.layers import Input,Dense,Reshape,Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "img_rows=32\n",
        "img_cols=32\n",
        "channels=3\n",
        "img_shape=(img_rows,img_cols,channels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNEYHm_hQ3i"
      },
      "source": [
        "hdf5_path=\"/content/gdrive/My Drive/LLD-icon.hdf5\"\n",
        "dataset=h5py.File(hdf5_path,\"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFd-fBTL42mQ"
      },
      "source": [
        "images, labels = (dataset['data'], dataset['labels/resnet/rc_64'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAxRJZuvZr90"
      },
      "source": [
        "def build_generator():\n",
        "  noise_shape=(100,)\n",
        "  model=Sequential()\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(1024))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Dense(np.prod(img_shape),activation='tanh'))\n",
        "  model.add(Reshape(img_shape))\n",
        "\n",
        "  model.summary()\n",
        "  noise=Input(shape=noise_shape)\n",
        "  img=model(noise)\n",
        "  \n",
        "  return Model(noise,img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTpB-4FA1KpN"
      },
      "source": [
        "def build_discriminator():\n",
        "  model.add(Flatten(input_shape=img_shape))\n",
        "  model=Sequential()\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.summary()\n",
        "  \n",
        "  img=Input(shape=img_shape)\n",
        "  validity=model(img)\n",
        "  return Model(img,validity)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAzEuhstH8ck"
      },
      "source": [
        "def train(epochs,batch_size=128,save_interval=500):\n",
        "  images=(images.astype(np.float32)-127.5)/127.5\n",
        "  half_batch=int(batch_size/2)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    idx=np.random.randint(0,img_shape[0],half_batch)\n",
        "    imgs=images[idx]\n",
        "    noise=np.random.normal(0,1,(half_batch,100))\n",
        "\n",
        "    gen_imgs=generator.predict(noise)\n",
        "    d_loss_real=discriminator.train_on_batch(imgs,np.ones((half_batch,1)))\n",
        "    d_loss_fake=discriminator.train_on_batch(gen_imgs,np.zeroes((half_batch,1))) \n",
        "\n",
        "    d_loss=0.5*(np.add(d_loss_real,d_loss_fake)) \n",
        "    noise=np.random.normal(0,1,(batch_size,100))\n",
        "    valid_y=np.array([1]*batch_size)\n",
        "    g_loss=combined.train_on_batch(noise,valid_y)\n",
        "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "    if epoch%save_interval==0:\n",
        "      save_imgs(epoch)\n",
        "       "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTT9KscZwkdS"
      },
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "    plt.close()"
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}